import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import os
import time
import sys
import random
import argparse
import logging
import wandb
import copy
import warnings
from collections import defaultdict
import torchvision
import torchvision.transforms as transforms
import math

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­ - Kaggleå…¼å®¹
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)
print(f"é¡¹ç›®æ ¹ç›®å½•: {project_root}")
print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")

# æ‰å¹³å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from model.resnet import EnhancedServerModel, TierAwareClientModel, ImprovedGlobalClassifier
from utils.tierhfl_aggregator import LayeredAggregator
from utils.tierhfl_client import TierHFLClientManager
from utils.tierhfl_loss import EnhancedStagedLoss
from analyze.tierhfl_analyze import validate_server_effectiveness
from analyze.diagnostic_monitor import EnhancedTierHFLDiagnosticMonitor

# === logging setup (æ”¾åœ¨ main.py çš„ import ä¹‹å) ===
import logging, sys
from pathlib import Path
from datetime import datetime

def setup_logging(run_name: str = "run",
                  log_dir: str = "logs",
                  console_level=logging.INFO,
                  file_level=logging.DEBUG) -> str:
    """
    åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å° + æ–‡ä»¶ï¼›å¼ºåˆ¶è¦†ç›–å·²æœ‰ handlerï¼Œé˜²æ­¢ basicConfig å¤±æ•ˆã€‚
    è¿”å›æ—¥å¿—æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²ã€‚
    """
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = Path(log_dir) / f"{run_name}_{ts}.log"

    fmt = "%(asctime)s | %(levelname)s | %(name)s:%(lineno)d - %(message)s"
    datefmt = "%H:%M:%S"

    logging.basicConfig(
        level=file_level,                       # æ ¹ logger è®° DEBUG åŠä»¥ä¸Šåˆ°æ–‡ä»¶
        format=fmt,
        datefmt=datefmt,
        handlers=[
            logging.StreamHandler(sys.stdout),  # æ§åˆ¶å°
            logging.FileHandler(log_path, mode="w", encoding="utf-8")  # æ–‡ä»¶
        ],
        force=True                              # å…³é”®ï¼šè¦†ç›–ä¹‹å‰ä»»ä½• handler/basicConfig
    )

    # æ§åˆ¶å°åªæ‰“ INFO+ï¼›æ–‡ä»¶ä»æ˜¯ DEBUG+
    logging.getLogger().handlers[0].setLevel(console_level)

    # ç¡®ä¿å‘½å loggerï¼ˆå¦‚ "TierHFL" ç­‰ï¼‰å†’æ³¡åˆ°æ ¹ loggerï¼Œä»è€Œä¹Ÿå†™æ–‡ä»¶
    for name in ["TierHFL", "analyze", "utils", "__main__"]:
        lg = logging.getLogger(name)
        lg.setLevel(logging.INFO)
        lg.propagate = True

    logging.info(f"æ—¥å¿—å·²å†™å…¥: {log_path}")
    return str(log_path)


# ========= EnhancedSerialTrainer (GPU-ready) =========
class EnhancedSerialTrainer:
    def __init__(self, client_manager, server_model, global_classifier, device="auto", use_amp=False):
        self.client_manager = client_manager
        self.server_model = server_model
        self.global_classifier = global_classifier

        # è®¾å¤‡é€‰æ‹©
        if device == "auto":
            if torch.cuda.is_available():
                self.device = torch.device("cuda")
            elif getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
                self.device = torch.device("mps")
            else:
                self.device = torch.device("cpu")
        else:
            self.device = torch.device(device)

        # æŠŠæœåŠ¡å™¨ä¾§ä¸¤ä¸ªæ¨¡å‹æ¬åˆ°è®¾å¤‡ä¸Š
        self.server_model.to(self.device)
        self.global_classifier.to(self.device)

        self.use_amp = bool(use_amp and self.device.type == "cuda")
        self.scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)

        self.client_models = {}
        self.cluster_map = {}
        self.cluster_server_models = {}
        self.cluster_global_classifiers = {}

        from utils.tierhfl_aggregator import LayeredAggregator
        # è®©èšåˆè®¡ç®—ä¹Ÿåœ¨ç›¸åŒ device ä¸Šåšï¼ˆå‡å°‘ CPU<->GPU æ‹–æ‹½ï¼‰
        self.layered_aggregator = LayeredAggregator(device=str(self.device))

        from utils.tierhfl_loss import EnhancedStagedLoss
        self.enhanced_loss = EnhancedStagedLoss(
            ls_eps=0.05,       # é™ä½æ ‡ç­¾å¹³æ»‘ï¼Œå‡å°‘å°ç±»ä¿¡æ¯è¢«æŠ¹å¹³
            entropy_coeff=2e-3  # å¢å¼ºå…¨å±€å¤´çš„è¾“å‡ºç†µçº¦æŸï¼Œé˜²æ­¢å•ç±»åå¥½
        )
        
        # å®¢æˆ·ç«¯æ€§èƒ½è¿½è¸ªï¼ˆç”¨äºåˆ†å±‚é‡‡æ ·ï¼‰
        self.client_performance = defaultdict(lambda: {'speed_score': 1.0, 'accuracy_ema': 0.0})
        
        # FedProxå‚æ•°
        self.mu = 0.0  # å°†åœ¨mainå‡½æ•°ä¸­è®¾ç½®

    def _prepare_models_for_round(self, server_model, global_classifier):
        """æœ¬è½®åªè°ƒç”¨ä¸€æ¬¡ï¼ŒæŠŠèšåˆåçš„æƒé‡å¤åˆ¶åˆ°traineræŒæœ‰çš„æ¨¡å‹ä¸Š"""
        self.server_model.load_state_dict(server_model.state_dict())
        self.global_classifier.load_state_dict(global_classifier.state_dict())
        # âš ï¸ æ³¨æ„ï¼šåœ¨åˆå§‹é˜¶æ®µéœ€è¦train()æ¨¡å¼ï¼Œä¸èƒ½å¼ºåˆ¶eval()
        self.server_model.to(self.device)         # ç”±å…·ä½“è®­ç»ƒé˜¶æ®µå†³å®štrain/evalæ¨¡å¼
        self.global_classifier.to(self.device).train()

    def _unwrap_loader(self, loader):
        """
        å¦‚æœè¯¯æŠŠ DataLoader å†æ¬¡ç”¨ DataLoader åŒ…äº†ä¸€å±‚ï¼Œåˆ™è§£åŒ…æˆå†…éƒ¨çš„é‚£ä¸€å±‚ï¼›
        å¦åˆ™åŸæ ·è¿”å›ã€‚
        """
        try:
            if isinstance(loader, DataLoader) and isinstance(getattr(loader, "dataset", None), DataLoader):
                return loader.dataset
        except Exception:
            pass
        return loader

    def register_client_models(self, client_models_dict):
        self.client_models.update(client_models_dict)

    def setup_training(self, cluster_map):
        self.cluster_map = cluster_map
        self.cluster_server_models = {}
        self.cluster_global_classifiers = {}
        # ç”¨å½“å‰ server/global classifier çš„æƒé‡ä½œä¸ºå„ç°‡åˆå€¼
        for cluster_id in cluster_map.keys():
            self.cluster_server_models[cluster_id] = copy.deepcopy(self.server_model.state_dict())
            self.cluster_global_classifiers[cluster_id] = copy.deepcopy(self.global_classifier.state_dict())
    
    def execute_round(self, round_idx, total_rounds, args, diagnostic_monitor=None):
        """æ‰§è¡Œä¸€è½®è®­ç»ƒ - é›†æˆå¢å¼ºç‰ˆç›‘æ§å’Œç»¼åˆåˆ†æ"""
        start_time = time.time()
        
        # ç›‘æ§å­¦ä¹ ç‡
        if diagnostic_monitor is not None:
            client_lrs = {}
            for client_id in range(len(self.client_models)):
                client = self.client_manager.get_client(client_id)
                if client:
                    client_lrs[client_id] = client.lr
            
            lr_analysis = diagnostic_monitor.monitor_learning_rates(client_lrs, round_idx)

        # ğŸ”¥ åˆ†å±‚é‡‡æ ·é€‰æ‹©æœ¬è½®å‚ä¸çš„å®¢æˆ·ç«¯
        selected_cluster_map = self.select_clients_for_round(
            self.cluster_map, args.client_fraction, round_idx
        )
        
        # ç»Ÿè®¡é€‰æ‹©çš„å®¢æˆ·ç«¯æ•°é‡
        total_selected = sum(len(clients) for clients in selected_cluster_map.values())
        total_available = sum(len(clients) for clients in self.cluster_map.values())
        logging.info(f"åˆ†å±‚é‡‡æ ·ï¼šé€‰æ‹©äº† {total_selected}/{total_available} ä¸ªå®¢æˆ·ç«¯å‚ä¸è®­ç»ƒ")

        # ç»“æœå®¹å™¨
        train_results = {}
        eval_results = {}
        shared_states = {}
        
        # ç¡®å®šå½“å‰è®­ç»ƒé˜¶æ®µ - ä½¿ç”¨å‚æ•°åŒ–è¾¹ç•Œè€Œéç¡¬ç¼–ç 
        if round_idx < args.initial_feature_rounds:  # ğŸ”¥ ä½¿ç”¨initial_feature_roundså‚æ•°
            training_phase = "initial"
            logging.info(f"è½®æ¬¡ {round_idx+1}/{total_rounds} - åˆå§‹ç‰¹å¾å­¦ä¹ é˜¶æ®µ")
        elif round_idx < args.initial_phase_rounds:
            training_phase = "initial"
            logging.info(f"è½®æ¬¡ {round_idx+1}/{total_rounds} - åˆå§‹é˜¶æ®µ")
        elif round_idx < args.initial_phase_rounds + args.alternating_phase_rounds:
            training_phase = "alternating"
            logging.info(f"è½®æ¬¡ {round_idx+1}/{total_rounds} - äº¤æ›¿è®­ç»ƒé˜¶æ®µ")
        else:
            training_phase = "fine_tuning"
            logging.info(f"è½®æ¬¡ {round_idx+1}/{total_rounds} - ç²¾ç»†è°ƒæ•´é˜¶æ®µ")
        
        # ä¾æ¬¡å¤„ç†æ¯ä¸ªèšç±»ï¼ˆä½¿ç”¨é€‰æ‹©åçš„å®¢æˆ·ç«¯ï¼‰
        for cluster_id, client_ids in selected_cluster_map.items():
            logging.info(f"å¤„ç†èšç±» {cluster_id}, åŒ…å« {len(client_ids)} ä¸ªå®¢æˆ·ç«¯")
            
            # åˆ›å»ºèšç±»ç‰¹å®šçš„æ¨¡å‹
            cluster_server = copy.deepcopy(self.server_model).to(self.device)
            cluster_server.load_state_dict(self.cluster_server_models[cluster_id])
            
            cluster_classifier = copy.deepcopy(self.global_classifier).to(self.device)
            cluster_classifier.load_state_dict(self.cluster_global_classifiers[cluster_id])
            
            # === ç›‘æ§èšç±»æ¨¡å‹ç¨³å®šæ€§ ===
            if diagnostic_monitor is not None:
                diagnostic_monitor.monitor_model_stability_fixed(
                    cluster_server.state_dict(), round_idx, f"server_cluster_{cluster_id}"
                )
                diagnostic_monitor.monitor_model_stability_fixed(
                    cluster_classifier.state_dict(), round_idx, f"classifier_cluster_{cluster_id}"
                )
            
            # å¤„ç†èšç±»ä¸­çš„æ¯ä¸ªå®¢æˆ·ç«¯
            for client_id in client_ids:
                client = self.client_manager.get_client(client_id)
                if not client or client_id not in self.client_models:
                    continue
                
                logging.info(f"è®­ç»ƒå®¢æˆ·ç«¯ {client_id} (Tier: {client.tier})")
                
                client_model = self.client_models[client_id].to(self.device)
                client.model = client_model
                
                # === ç›‘æ§å®¢æˆ·ç«¯æ¨¡å‹ç¨³å®šæ€§ ===
                if diagnostic_monitor is not None:
                    diagnostic_monitor.monitor_model_stability_fixed(
                        client_model.state_dict(), round_idx, f"client_{client_id}"
                    )
                
                # æ ¹æ®è®­ç»ƒé˜¶æ®µæ‰§è¡Œè®­ç»ƒ
                if training_phase == "initial":
                    train_result = self._train_initial_phase_enhanced(
                        client_id,
                        client,
                        cluster_server,      # æˆ–è€…ä½ çš„å˜é‡å server_model
                        cluster_classifier, # æˆ–è€…ä½ çš„å˜é‡å global_classifier
                        round_idx,
                        diagnostic_monitor
                    )

                    
                elif training_phase == "alternating":
                    train_result = self._train_alternating_phase_enhanced(
                        client, client_model, cluster_server, cluster_classifier,
                        round_idx, total_rounds, diagnostic_monitor, args)
                    
                else:  # fine_tuning
                    train_result = self._train_fine_tuning_phase_enhanced(
                        client, client_model, cluster_server, cluster_classifier,
                        round_idx, total_rounds, diagnostic_monitor, args)
                
                # ä¿å­˜ç»“æœ
                train_results[client_id] = train_result
                
                # ğŸ”¥ æ›´æ–°å®¢æˆ·ç«¯æ€§èƒ½æŒ‡æ ‡
                training_time = train_result.get('time_cost', 1.0)
                accuracy = train_result.get('global_accuracy', train_result.get('local_accuracy', 0.0))
                self.update_client_performance(client_id, training_time, accuracy)
                
                # è¯„ä¼°å®¢æˆ·ç«¯
                eval_result = self._evaluate_client(
                    client, client_model, cluster_server, cluster_classifier)
                eval_result['cluster_id'] = cluster_id  # æ·»åŠ èšç±»ID
                eval_results[client_id] = eval_result
                
                # ä¿å­˜å…±äº«å±‚çŠ¶æ€
                shared_state = {}
                for name, param in client_model.named_parameters():
                    if 'shared_base' in name:
                        shared_state[name] = param.data.clone().cpu()
                shared_states[client_id] = shared_state
                
                # æ›´æ–°å®¢æˆ·ç«¯æ¨¡å‹
                self.client_models[client_id] = client_model.cpu()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()


            
            # ä¿å­˜èšç±»æ¨¡å‹
            self.cluster_server_models[cluster_id] = cluster_server.cpu().state_dict()
            self.cluster_global_classifiers[cluster_id] = cluster_classifier.cpu().state_dict()
        
        # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
        training_time = time.time() - start_time
        
        # === ç”Ÿæˆç»¼åˆè¯Šæ–­æŠ¥å‘Š ===
        if diagnostic_monitor is not None:
            comprehensive_report = diagnostic_monitor.comprehensive_diagnostic_report(round_idx)
            
            # è®°å½•å…³é”®å‘ç°
            if comprehensive_report['overall_health'] == 'critical':
                logging.error(f"è½®æ¬¡{round_idx+1}: æ£€æµ‹åˆ°ä¸¥é‡é—®é¢˜!")
                for issue in comprehensive_report['critical_issues']:
                    logging.error(f"  - {issue}")
            
            if comprehensive_report['recommendations']:
                logging.info(f"è½®æ¬¡{round_idx+1} ä¼˜åŒ–å»ºè®®:")
                for rec in comprehensive_report['recommendations']:
                    logging.info(f"  - {rec}")
        
        return train_results, eval_results, shared_states, training_time

    # === é˜¶æ®µ1ï¼šä»…è®­ç»ƒâ€œå…¨å±€è·¯å¾„â€ï¼ˆæœåŠ¡å™¨ç‰¹å¾ + å…¨å±€åˆ†ç±»å™¨ï¼‰===
    # åœ¨ class EnhancedSerialTrainer å†…éƒ¨ï¼Œå®Œæ•´æ›¿æ¢è¿™ä¸ªå‡½æ•°
    def _train_initial_phase_enhanced(
        self, client_id, client, server_model, global_classifier, round_idx, diagnostic_monitor=None
    ):
        # ---- ç»Ÿä¸€è®¾å¤‡ ----
        client_model = self.client_models[client_id]
        client_model.to(self.device).train()
        self.server_model.load_state_dict(server_model.state_dict())
        self.global_classifier.load_state_dict(global_classifier.state_dict())
        
        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šè®©server_modelä¹Ÿå‚ä¸è®­ç»ƒï¼Œè€Œä¸æ˜¯eval()
        self.server_model.to(self.device).train()        # ä»eval()æ”¹ä¸ºtrain()
        self.global_classifier.to(self.device).train()

        # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸ºserver_modelå’Œglobal_classifieråˆ†åˆ«åˆ›å»ºä¼˜åŒ–å™¨
        opt_server = torch.optim.SGD(
            self.server_model.parameters(), lr=client.lr, momentum=0.9, weight_decay=5e-4
        )
        opt_classifier = torch.optim.SGD(
            self.global_classifier.parameters(), lr=client.lr, momentum=0.9, weight_decay=5e-4
        )

        running_loss, total, correct = 0.0, 0, 0
        use_amp = (self.device.type == "cuda")

        for data, target in client.train_data:
            data   = data.to(self.device, non_blocking=True)
            target = target.to(self.device, non_blocking=True)

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šä¸¤ä¸ªä¼˜åŒ–å™¨éƒ½è¦æ¸…é›¶æ¢¯åº¦
            opt_server.zero_grad(set_to_none=True)
            opt_classifier.zero_grad(set_to_none=True)
            
            with torch.cuda.amp.autocast(enabled=use_amp):
                local_logits, shared_features, _ = client_model(data)
                server_features = self.server_model(shared_features)
                global_logits   = self.global_classifier(server_features)
                total_loss, _, _ = self.enhanced_loss.stage1_loss(
                    global_logits, target, shared_features=shared_features
                )

            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šAMPæ”¯æŒä¸¤ä¸ªä¼˜åŒ–å™¨
            if use_amp:
                self.scaler.scale(total_loss).backward()
                # å…ˆunscaleå†åšæ¢¯åº¦è£å‰ª
                self.scaler.unscale_(opt_server)
                self.scaler.unscale_(opt_classifier)
                torch.nn.utils.clip_grad_norm_(list(self.server_model.parameters()), 1.0)
                torch.nn.utils.clip_grad_norm_(list(self.global_classifier.parameters()), 1.0)
                # ä¸¤ä¸ªä¼˜åŒ–å™¨éƒ½è¦step
                self.scaler.step(opt_server)
                self.scaler.step(opt_classifier)
                self.scaler.update()
            else:
                total_loss.backward()
                torch.nn.utils.clip_grad_norm_(list(self.server_model.parameters()), 1.0)
                torch.nn.utils.clip_grad_norm_(list(self.global_classifier.parameters()), 1.0)
                opt_server.step()
                opt_classifier.step()

            running_loss += float(total_loss.detach())
            with torch.no_grad():
                pred = global_logits.argmax(dim=1)
                correct += (pred == target).sum().item()
                total   += target.size(0)

        train_acc = 100.0 * correct / max(1, total)
        train_samples = len(client.train_data.dataset) if hasattr(client.train_data, 'dataset') else total
        return {"train_loss": running_loss / max(1, len(client.train_data)), "train_acc": train_acc, "train_samples": train_samples}

    def _train_alternating_phase_enhanced(
        self, client, client_model, server_model, classifier, round_idx, total_rounds, diagnostic_monitor=None, args=None
    ):
        import time
        from torch.nn.utils import clip_grad_norm_
        from torch.optim.lr_scheduler import CosineAnnealingLR

        start = time.time()
        # ---- ç»Ÿä¸€è®¾å¤‡ ----
        client_model.to(self.device).train()
        server_model.to(self.device).train()
        classifier.to(self.device).train()
        use_amp = (self.device.type == "cuda")

        # å…è®¸å…¨éƒ¨åˆ†æ”¯è®­ç»ƒï¼ˆå…±äº«+ä¸ªæ€§åŒ–+æœ¬åœ°å¤´+æœåŠ¡å™¨+å…¨å±€å¤´ï¼‰
        for p in client_model.parameters():
            p.requires_grad = True

        # å‚æ•°åˆ†ç»„
        shared_params   = [p for n, p in client_model.named_parameters() if ('shared_base' in n and p.requires_grad)]
        personal_params = [p for n, p in client_model.named_parameters() if ('shared_base' not in n and p.requires_grad)]
        server_params   = list(server_model.parameters())
        global_params   = list(classifier.parameters())

        # ä¼˜åŒ–å™¨ï¼ˆåœ¨ to(device) ä¹‹åï¼‰
        opt_shared    = torch.optim.SGD(shared_params,   lr=client.lr, momentum=0.9, weight_decay=client.wd) if shared_params else None
        opt_personal  = torch.optim.SGD(personal_params, lr=client.lr, momentum=0.9, weight_decay=client.wd) if personal_params else None
        opt_server    = torch.optim.SGD(server_params,   lr=client.lr, momentum=0.9, weight_decay=client.wd)
        opt_global    = torch.optim.SGD(global_params,   lr=client.lr, momentum=0.9, weight_decay=client.wd)

        sch_shared    = CosineAnnealingLR(opt_shared,   T_max=max(1, client.local_epochs), eta_min=0.0) if opt_shared else None
        sch_personal  = CosineAnnealingLR(opt_personal, T_max=max(1, client.local_epochs), eta_min=0.0) if opt_personal else None
        sch_server    = CosineAnnealingLR(opt_server,   T_max=max(1, client.local_epochs), eta_min=0.0)
        sch_global    = CosineAnnealingLR(opt_global,   T_max=max(1, client.local_epochs), eta_min=0.0)

        # ğŸ”¥ ä½¿ç”¨å‚æ•°æ§åˆ¶çš„åŠ¨æ€alphaè°ƒæ•´
        if args is not None:
            progress = round_idx / max(1, total_rounds)
            alpha = args.init_alpha - (args.init_alpha - args.min_alpha) * progress
        else:
            # å›é€€åˆ°é»˜è®¤å€¼
            progress = round_idx / max(1, total_rounds)
            alpha = 0.6 - (0.6 - 0.4) * progress

        stat = {'total_loss': 0.0, 'batch_count': 0, 'local_correct': 0, 'global_correct': 0, 'total': 0}

        for _ in range(client.local_epochs):
            for data, target in client.train_data:
                data   = data.to(self.device, non_blocking=True)
                target = target.to(self.device, non_blocking=True)

                if opt_shared:   opt_shared.zero_grad(set_to_none=True)
                if opt_personal: opt_personal.zero_grad(set_to_none=True)
                opt_server.zero_grad(set_to_none=True)
                opt_global.zero_grad(set_to_none=True)

                with torch.cuda.amp.autocast(enabled=use_amp):
                    local_logits, shared_features, personal_features = client_model(data)
                    server_features = server_model(shared_features)
                    global_logits   = classifier(server_features)

                    total_loss, local_loss, global_loss, balance_loss = self.enhanced_loss.stage2_3_loss(
                        local_logits, global_logits, target,
                        personal_gradients=None, global_gradients=None,
                        shared_features=shared_features, alpha=alpha
                    )

                if use_amp:
                    self.scaler.scale(total_loss).backward()
                    # å¯é€‰ï¼šå…±äº«å±‚æ¢¯åº¦æŠ•å½±
                    # self.enhanced_loss.apply_gradient_projection(client_model, local_loss, global_loss, alpha_stage=alpha)
                    if opt_shared:   self.scaler.unscale_(opt_shared);   clip_grad_norm_(shared_params,   1.0)
                    if opt_personal: self.scaler.unscale_(opt_personal); clip_grad_norm_(personal_params, 1.0)
                    self.scaler.unscale_(opt_server); clip_grad_norm_(server_params, 1.0)
                    self.scaler.unscale_(opt_global); clip_grad_norm_(global_params, 1.0)

                    if opt_shared:   self.scaler.step(opt_shared)
                    if opt_personal: self.scaler.step(opt_personal)
                    self.scaler.step(opt_server)
                    self.scaler.step(opt_global)
                    self.scaler.update()
                else:
                    total_loss.backward()
                    if opt_shared:   clip_grad_norm_(shared_params,   1.0)
                    if opt_personal: clip_grad_norm_(personal_params, 1.0)
                    clip_grad_norm_(server_params, 1.0)
                    clip_grad_norm_(global_params, 1.0)

                    if opt_shared:   opt_shared.step()
                    if opt_personal: opt_personal.step()
                    opt_server.step()
                    opt_global.step()

                stat['total_loss']   += float(total_loss.item()); stat['batch_count'] += 1
                with torch.no_grad():
                    stat['local_correct']  += (local_logits.argmax(1)  == target).sum().item()
                    stat['global_correct'] += (global_logits.argmax(1) == target).sum().item()
                    stat['total']          += target.size(0)

            if sch_shared:   sch_shared.step()
            if sch_personal: sch_personal.step()
            sch_server.step(); sch_global.step()

        avg_loss   = stat['total_loss'] / max(1, stat['batch_count'])
        acc_local  = 100.0 * stat['local_correct']  / max(1, stat['total'])
        acc_global = 100.0 * stat['global_correct'] / max(1, stat['total'])
        train_samples = len(client.train_data.dataset) if hasattr(client.train_data, 'dataset') else stat['total']

        return {
            'train_loss': avg_loss,
            'local_accuracy': acc_local,
            'global_accuracy': acc_global,
            'time_cost': time.time() - start,
            'train_samples': train_samples
        }


    
    
    def _train_fine_tuning_phase_enhanced(self, client, client_model, server_model, global_classifier,
                                          round_idx, total_rounds, diagnostic_monitor=None, args=None):
        import time
        from torch.nn.utils import clip_grad_norm_
        from torch.optim.lr_scheduler import CosineAnnealingLR
        start = time.time()

        # ä½¿ç”¨trainerçš„æ¨¡å‹è€Œéä¼ å…¥å‚æ•°ï¼Œç¡®ä¿æƒé‡ç´¯ç§¯
        client_model.to(self.device)
        self.server_model.to(self.device)
        self.global_classifier.to(self.device)

        # å†»ç»“å…±äº«å±‚ï¼Œä¸»è®­ä¸ªæ€§åŒ–ä¸æœ¬åœ°å¤´ï¼›server/global å°æ­¥å¾®è°ƒ
        for n,p in client_model.named_parameters():
            p.requires_grad = ('shared_base' not in n)

        client_model.train(); self.server_model.train(); self.global_classifier.train()

        personal_params = [p for p in client_model.parameters() if p.requires_grad]
        opt_personal = torch.optim.SGD(personal_params, lr=client.lr, momentum=0.9, weight_decay=client.wd)
        opt_server   = torch.optim.SGD(self.server_model.parameters(),  lr=client.lr*0.2, momentum=0.9, weight_decay=client.wd)
        opt_global   = torch.optim.SGD(self.global_classifier.parameters(), lr=client.lr*0.2, momentum=0.9, weight_decay=client.wd)

        sch_personal = CosineAnnealingLR(opt_personal, T_max=max(1, client.local_epochs), eta_min=0.0)
        sch_server   = CosineAnnealingLR(opt_server,   T_max=max(1, client.local_epochs), eta_min=0.0)
        sch_global   = CosineAnnealingLR(opt_global,   T_max=max(1, client.local_epochs), eta_min=0.0)

        stat = {'total_loss':0.0,'batch_count':0,'local_correct':0,'global_correct':0,'total':0}
        # ğŸ”¥ ä½¿ç”¨å‚æ•°æ§åˆ¶çš„åŠ¨æ€alphaè°ƒæ•´
        if args is not None:
            progress = round_idx / max(1, total_rounds)
            alpha = args.init_alpha - (args.init_alpha - args.min_alpha) * progress
        else:
            # å›é€€åˆ°é»˜è®¤å€¼
            progress = round_idx / max(1, total_rounds)
            alpha = 0.6 - (0.6 - 0.4) * progress

        train_loader = self._unwrap_loader(client.train_data)

        for _ in range(client.local_epochs):
            for data, target in train_loader:
                data, target = data.to(self.device, non_blocking=True), target.to(self.device, non_blocking=True)
                opt_personal.zero_grad(); opt_server.zero_grad(); opt_global.zero_grad()

                with torch.cuda.amp.autocast(enabled=self.use_amp and torch.cuda.is_available()):
                    local_logits, shared_features, personal_features = client_model(data)
                    server_features = self.server_model(shared_features)
                    global_logits   = self.global_classifier(server_features)
                    total_loss, local_loss, global_loss, balance_loss = self.enhanced_loss.stage2_3_loss(
                        local_logits, global_logits, target,
                        personal_gradients=None, global_gradients=None,
                        shared_features=shared_features, alpha=alpha
                    )

                if self.use_amp and torch.cuda.is_available():
                    self.scaler.scale(total_loss).backward()
                    self.scaler.unscale_(opt_personal); self.scaler.unscale_(opt_server); self.scaler.unscale_(opt_global)
                else:
                    total_loss.backward()

                clip_grad_norm_(personal_params, max_norm=1.0)
                for group in [self.server_model.parameters(), self.global_classifier.parameters()]:
                    clip_grad_norm_(list(group), max_norm=1.0)

                if self.use_amp and torch.cuda.is_available():
                    self.scaler.step(opt_personal); self.scaler.step(opt_server); self.scaler.step(opt_global); self.scaler.update()
                else:
                    opt_personal.step(); opt_server.step(); opt_global.step()

                stat['total_loss'] += float(total_loss.item()); stat['batch_count'] += 1
                with torch.no_grad():
                    stat['local_correct']  += (local_logits.argmax(1)  == target).sum().item()
                    stat['global_correct'] += (global_logits.argmax(1) == target).sum().item()
                    stat['total']          += target.size(0)

            sch_personal.step(); sch_server.step(); sch_global.step()

        avg_loss   = stat['total_loss'] / max(1, stat['batch_count'])
        acc_local  = 100.0 * stat['local_correct']  / max(1, stat['total'])
        acc_global = 100.0 * stat['global_correct'] / max(1, stat['total'])
        train_samples = len(client.train_data.dataset) if hasattr(client.train_data, 'dataset') else stat['total']
        return {'train_loss': avg_loss, 'local_accuracy': acc_local, 'global_accuracy': acc_global,
                'time_cost': time.time()-start, 'train_samples': train_samples}





    def _train_personal_path_enhanced(self, client, client_model, round_idx, total_rounds, diagnostic_monitor=None):
        import time
        import torch.nn.functional as F
        from torch.nn.utils import clip_grad_norm_
        from torch.optim.lr_scheduler import CosineAnnealingLR

        start = time.time()
        client_model.train()

        # 1) å†»ç»“å…±äº«å±‚ï¼Œåªè®­ä¸ªæ€§åŒ–è·¯å¾„ + æœ¬åœ°å¤´
        for n, p in client_model.named_parameters():
            if 'shared_base' in n:
                p.requires_grad = False
            else:
                p.requires_grad = True

        trainable_params = [p for p in client_model.parameters() if p.requires_grad]
        opt_personal = torch.optim.Adam(trainable_params, lr=client.lr, weight_decay=client.wd)
        sch_personal = CosineAnnealingLR(opt_personal, T_max=max(1, client.local_epochs), eta_min=0.0)

        stat = {'local_loss': 0.0, 'correct': 0, 'total': 0, 'batch_count': 0}

        for _ in range(client.local_epochs):
            for data, target in client.train_data:
                data, target = data.to(self.device), target.to(self.device)
                opt_personal.zero_grad()
                local_logits, shared_f, personal_f = client_model(data)
                loss = F.cross_entropy(local_logits, target)
                loss.backward()
                clip_grad_norm_(trainable_params, max_norm=1.0)
                opt_personal.step()

                stat['local_loss'] += float(loss.item()); stat['batch_count'] += 1
                with torch.no_grad():
                    pred = local_logits.argmax(dim=1)
                    stat['correct'] += (pred == target).sum().item()
                    stat['total'] += target.size(0)

            sch_personal.step()

        # è§£å†»å›å»ï¼Œä¾›åç»­é˜¶æ®µä½¿ç”¨
        for p in client_model.parameters(): p.requires_grad = True

        avg_local = stat['local_loss'] / max(1, stat['batch_count'])
        acc_local = 100.0 * stat['correct'] / max(1, stat['total'])
        train_samples = len(client.train_data.dataset) if hasattr(client.train_data, 'dataset') else stat['total']
        return {'local_loss': avg_local, 'local_accuracy': acc_local, 'time_cost': time.time() - start, 'train_samples': train_samples}


    def _train_global_path_enhanced(self, client, client_model, server_model, classifier, 
                                  shared_lr, round_idx, total_rounds, diagnostic_monitor=None, epochs=1):
        """å¢å¼ºç‰ˆå…¨å±€è·¯å¾„è®­ç»ƒ"""
        start_time = time.time()
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        client_model.train()
        server_model.train()
        classifier.train()
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        shared_optimizer = torch.optim.Adam(
            [p for n, p in client_model.named_parameters() if 'shared_base' in n], 
            lr=shared_lr
        )
        server_optimizer = torch.optim.Adam(server_model.parameters(), lr=0.001)
        classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'global_loss': 0.0,
            'local_loss': 0.0,
            'balance_loss': 0.0,
            'total_loss': 0.0,
            'correct': 0,
            'total': 0,
            'batch_count': 0
        }
        
        # è®¡ç®—alphaå€¼
        progress = round_idx / total_rounds
        alpha = 0.3 + 0.4 * progress  # ä¸ªæ€§åŒ–æƒé‡éšè®­ç»ƒè¿›åº¦å¢åŠ 
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(epochs):
            for batch_idx, (data, target) in enumerate(client.train_data):
                data, target = data.to(self.device), target.to(self.device)
                
                # å‰å‘ä¼ æ’­
                local_logits, shared_features, personal_features = client_model(data)
                server_features = server_model(shared_features)
                global_logits = classifier(server_features)
                
                # è®¡ç®—æŸå¤±
                local_loss = F.cross_entropy(local_logits, target)
                global_loss = F.cross_entropy(global_logits, target)
                
                # è®¡ç®—æ¢¯åº¦ç”¨äºç‰¹å¾å¹³è¡¡æŸå¤±
                # ä¸ºé¿å…è®¡ç®—å›¾å¤æ‚åŒ–ï¼Œæˆ‘ä»¬ç®€åŒ–ç‰¹å¾å¹³è¡¡æŸå¤±
                balance_loss = torch.tensor(0.0, device=global_logits.device)
                
                # ä½¿ç”¨å¢å¼ºæŸå¤±å‡½æ•°
                total_loss, local_loss_calc, global_loss_calc, balance_loss = self.enhanced_loss.stage2_3_loss(
                    local_logits, global_logits, target, 
                    personal_gradients=None, global_gradients=None,  # ç®€åŒ–å®ç°
                    shared_features=shared_features, alpha=alpha
                )
                
                # æ¸…é™¤æ¢¯åº¦
                shared_optimizer.zero_grad()
                server_optimizer.zero_grad()
                classifier_optimizer.zero_grad()
                
                # åå‘ä¼ æ’­
                total_loss.backward()
                
                # åº”ç”¨æ¢¯åº¦æŠ•å½±ï¼ˆç®€åŒ–ç‰ˆï¼‰
                # åœ¨å®é™…å®ç°ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œåº”ç”¨æ¢¯åº¦æŠ•å½±
                # ä½†ä¸ºäº†ä¿æŒä»£ç ç®€æ´ï¼Œæš‚æ—¶è·³è¿‡å¤æ‚çš„æ¢¯åº¦æŠ•å½±
                
                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(
                    [p for n, p in client_model.named_parameters() if 'shared_base' in n], 
                    max_norm=0.5
                )
                
                # æ›´æ–°å‚æ•°
                shared_optimizer.step()
                server_optimizer.step()
                classifier_optimizer.step()
                
                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                stats['global_loss'] += global_loss.item()
                stats['local_loss'] += local_loss.item()
                stats['balance_loss'] += balance_loss.item()
                stats['total_loss'] += total_loss.item()
                stats['batch_count'] += 1
                
                _, pred = global_logits.max(1)
                stats['correct'] += pred.eq(target).sum().item()
                stats['total'] += target.size(0)
        
        # è®¡ç®—å¹³å‡å€¼
        for key in ['global_loss', 'local_loss', 'balance_loss', 'total_loss']:
            if stats['batch_count'] > 0:
                stats[key] /= stats['batch_count']
        
        if stats['total'] > 0:
            stats['global_accuracy'] = 100.0 * stats['correct'] / stats['total']
        else:
            stats['global_accuracy'] = 0.0
        
        # è·å–è®­ç»ƒæ ·æœ¬æ•°
        train_samples = len(client.train_data.dataset) if hasattr(client.train_data, 'dataset') else stats['total']
        
        return {
            'global_loss': stats['global_loss'],
            'local_loss': stats['local_loss'],
            'balance_loss': stats['balance_loss'],
            'total_loss': stats['total_loss'],
            'global_accuracy': stats['global_accuracy'],
            'time_cost': time.time() - start_time,
            'train_samples': train_samples
        }

    def _evaluate_client(self, client, client_model, server_model, global_classifier):
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°è€Œéselfçš„æ¨¡å‹ï¼Œç¡®ä¿èšç±»ä¸“å±æ¨¡å‹è¢«æ­£ç¡®ä½¿ç”¨
        client_model.eval()
        server_model.eval()
        global_classifier.eval()

        # å…³é”®ï¼šè§£åŒ… DataLoader
        test_loader = self._unwrap_loader(client.test_data)

        total, correct_local, correct_global = 0, 0, 0
        loss_sum = 0.0

        with torch.no_grad():
            for data, target in test_loader:
                data   = data.to(self.device, non_blocking=True)
                target = target.to(self.device, non_blocking=True)

                local_logits, shared_features, _ = client_model(data)
                server_features = server_model(shared_features)            # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°
                global_logits   = global_classifier(server_features)       # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°

                loss_sum += F.cross_entropy(global_logits, target, reduction="sum").item()
                pred_local  = local_logits.argmax(dim=1)
                pred_global = global_logits.argmax(dim=1)

                correct_local  += (pred_local  == target).sum().item()
                correct_global += (pred_global == target).sum().item()
                total += target.size(0)

        return {
            "test_loss":       loss_sum / max(1, total),
            "local_accuracy":  100.0 * correct_local  / max(1, total),
            "global_accuracy": 100.0 * correct_global / max(1, total),
        }

    def aggregate_client_shared_layers(self, shared_states, eval_results):
        """ä½¿ç”¨åˆ†å±‚èšåˆå™¨èšåˆå®¢æˆ·ç«¯å…±äº«å±‚"""
        if not shared_states:
            return {}
        
        return self.layered_aggregator.aggregate_shared_layers(shared_states, eval_results)

    def aggregate_server_models(self, eval_results=None):
        """ä½¿ç”¨åˆ†å±‚èšåˆå™¨èšåˆæœåŠ¡å™¨æ¨¡å‹"""
        if not self.cluster_server_models:
            return {}
        
        return self.layered_aggregator.aggregate_server_models(self.cluster_server_models, eval_results)

    def aggregate_global_classifiers(self, eval_results=None):
        """ä½¿ç”¨åˆ†å±‚èšåˆå™¨èšåˆå…¨å±€åˆ†ç±»å™¨"""
        if not self.cluster_global_classifiers:
            return {}
        
        return self.layered_aggregator.aggregate_global_classifiers(self.cluster_global_classifiers, eval_results)

    def update_client_shared_layers(self, aggregated_shared_state):
        """æ›´æ–°æ‰€æœ‰å®¢æˆ·ç«¯çš„å…±äº«å±‚å‚æ•°"""
        if not aggregated_shared_state:
            return False
        
        for client_id, model in self.client_models.items():
            for name, param in model.named_parameters():
                if 'shared_base' in name and name in aggregated_shared_state:
                    param.data.copy_(aggregated_shared_state[name])
        
        return True
    
    def update_server_models(self, aggregated_server_model, aggregated_global_classifier=None):
        """æ›´æ–°æ‰€æœ‰èšç±»çš„æœåŠ¡å™¨æ¨¡å‹å’Œå…¨å±€åˆ†ç±»å™¨"""
        updated = False
        
        # æ›´æ–°æœåŠ¡å™¨æ¨¡å‹
        if aggregated_server_model:
            # æ›´æ–°ä¸»æœåŠ¡å™¨æ¨¡å‹
            for name, param in self.server_model.named_parameters():
                if name in aggregated_server_model:
                    param.data.copy_(aggregated_server_model[name])
            
            # æ›´æ–°æ‰€æœ‰èšç±»çš„æœåŠ¡å™¨æ¨¡å‹
            for cluster_id in self.cluster_server_models:
                self.cluster_server_models[cluster_id] = copy.deepcopy(self.server_model.state_dict())
            
            updated = True
        
        # æ›´æ–°å…¨å±€åˆ†ç±»å™¨
        if aggregated_global_classifier:
            # æ›´æ–°ä¸»å…¨å±€åˆ†ç±»å™¨
            for name, param in self.global_classifier.named_parameters():
                if name in aggregated_global_classifier:
                    param.data.copy_(aggregated_global_classifier[name])
            
            # æ›´æ–°æ‰€æœ‰èšç±»çš„å…¨å±€åˆ†ç±»å™¨
            for cluster_id in self.cluster_global_classifiers:
                self.cluster_global_classifiers[cluster_id] = copy.deepcopy(self.global_classifier.state_dict())
            
            updated = True
        
        return updated

    def select_clients_for_round(self, cluster_map, client_fraction=0.7, round_idx=0):
        """åˆ†å±‚é‡‡æ ·é€‰æ‹©æœ¬è½®å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯"""
        selected_cluster_map = {}
        
        for cluster_id, client_ids in cluster_map.items():
            if len(client_ids) == 0:
                selected_cluster_map[cluster_id] = []
                continue
                
            # è®¡ç®—è¯¥èšç±»ä¸­åº”é€‰æ‹©çš„å®¢æˆ·ç«¯æ•°é‡
            k = max(1, int(len(client_ids) * client_fraction))
            
            if k >= len(client_ids):
                # å¦‚æœéœ€è¦é€‰æ‹©çš„æ•°é‡å¤§äºç­‰äºæ€»æ•°ï¼Œé€‰æ‹©æ‰€æœ‰å®¢æˆ·ç«¯
                selected_cluster_map[cluster_id] = client_ids
            else:
                # åŸºäºtierå’Œperformanceè¿›è¡ŒåŠ æƒé‡‡æ ·
                weights = []
                for cid in client_ids:
                    client = self.client_manager.get_client(cid)
                    if client:
                        # åŸºç¡€æƒé‡ï¼štierè¶Šé«˜æƒé‡è¶Šå¤§(tier=1æœ€é«˜ï¼Œtier=4æœ€ä½)
                        tier_weight = 5 - client.tier  # tier 1->4, tier 2->3, tier 3->2, tier 4->1
                        
                        # æ€§èƒ½æƒé‡ï¼šåŸºäºæœ€è¿‘çš„é€Ÿåº¦å’Œå‡†ç¡®ç‡
                        perf = self.client_performance[cid]
                        speed_weight = perf['speed_score'] 
                        acc_weight = perf['accuracy_ema'] + 0.1  # åŠ 0.1é¿å…é›¶æƒé‡
                        
                        # ç»¼åˆæƒé‡
                        total_weight = tier_weight * speed_weight * acc_weight
                        weights.append(max(total_weight, 0.01))  # ç¡®ä¿æœ€å°æƒé‡
                    else:
                        weights.append(0.01)
                
                # å½’ä¸€åŒ–æƒé‡
                weights = np.array(weights)
                weights = weights / weights.sum()
                
                # åŠ æƒéšæœºé‡‡æ ·
                try:
                    selected_indices = np.random.choice(
                        len(client_ids), size=k, replace=False, p=weights
                    )
                    selected_cluster_map[cluster_id] = [client_ids[i] for i in selected_indices]
                except:
                    # å¦‚æœé‡‡æ ·å¤±è´¥ï¼Œé€€å›åˆ°éšæœºé‡‡æ ·
                    selected_cluster_map[cluster_id] = np.random.choice(client_ids, size=k, replace=False).tolist()
        
        return selected_cluster_map
    
    def update_client_performance(self, client_id, training_time, accuracy):
        """æ›´æ–°å®¢æˆ·ç«¯æ€§èƒ½æŒ‡æ ‡"""
        perf = self.client_performance[client_id]
        
        # æ›´æ–°é€Ÿåº¦å¾—åˆ†(EMA)
        speed_score = 1.0 / (training_time + 1e-6)  # æ—¶é—´è¶ŠçŸ­å¾—åˆ†è¶Šé«˜
        perf['speed_score'] = 0.8 * perf['speed_score'] + 0.2 * speed_score
        
        # æ›´æ–°å®¢æˆ·ç«¯æ€§èƒ½æŒ‡æ ‡
        perf['accuracy_ema'] = 0.8 * perf['accuracy_ema'] + 0.2 * accuracy

    def compute_prox_loss(self, local_model, global_model, mu=0.0):
        """è®¡ç®—FedProxæ­£åˆ™åŒ–é¡¹"""
        if mu <= 0:
            return 0.0
        
        prox_loss = 0.0
        with torch.no_grad():
            for local_param, global_param in zip(local_model.parameters(), global_model.parameters()):
                prox_loss += torch.sum((local_param - global_param) ** 2)
        
        return mu / 2.0 * prox_loss


def set_seed(seed=42):
    import random, numpy as np, torch
    random.seed(seed); np.random.seed(seed); torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True


def parse_arguments():
    parser = argparse.ArgumentParser(description='TierHFL: åˆ†å±‚å¼‚æ„è”é‚¦å­¦ä¹ æ¡†æ¶ (å¢å¼ºç‰ˆæœ¬)')
    
    # å®éªŒæ ‡è¯†
    parser.add_argument('--running_name', default="TierHFL_Enhanced", type=str, help='å®éªŒåç§°')
    
    # ä¼˜åŒ–ç›¸å…³å‚æ•°
    parser.add_argument('--lr', default=0.005, type=float, help='åˆå§‹å­¦ä¹ ç‡')
    parser.add_argument('--lr_factor', default=0.9, type=float, help='å­¦ä¹ ç‡è¡°å‡å› å­')
    parser.add_argument('--wd', help='æƒé‡è¡°å‡å‚æ•°', type=float, default=1e-4)
    
    # æ¨¡å‹ç›¸å…³å‚æ•°
    parser.add_argument('--model', type=str, default='resnet56', help='ä½¿ç”¨çš„ç¥ç»ç½‘ç»œ (resnet56 æˆ– resnet110)')
    
    # æ•°æ®åŠ è½½å’Œé¢„å¤„ç†ç›¸å…³å‚æ•°
    parser.add_argument('--dataset', type=str, default='fashion_mnist', 
                       help='è®­ç»ƒæ•°æ®é›† (cifar10, cifar100, fashion_mnist, cinic10)')
    parser.add_argument('--data_dir', type=str, default='./data', help='æ•°æ®ç›®å½•')
    parser.add_argument('--partition_method', type=str, default='hetero', help='æœ¬åœ°å·¥ä½œèŠ‚ç‚¹ä¸Šæ•°æ®é›†çš„åˆ’åˆ†æ–¹å¼')
    parser.add_argument('--partition_alpha', type=float, default=0.5, help='åˆ’åˆ†å‚æ•°alpha')
    
    # è”é‚¦å­¦ä¹ ç›¸å…³å‚æ•°
    parser.add_argument('--client_epoch', default=5, type=int, help='å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒè½®æ•°')
    parser.add_argument('--client_number', type=int, default=5, help='å®¢æˆ·ç«¯æ•°é‡')
    parser.add_argument('--batch_size', type=int, default=256, help='è®­ç»ƒçš„è¾“å…¥æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--rounds', default=100, type=int, help='è”é‚¦å­¦ä¹ è½®æ•°')
    parser.add_argument('--n_clusters', default=3, type=int, help='å®¢æˆ·ç«¯èšç±»æ•°é‡')
    
    # TierHFLç‰¹æœ‰å‚æ•°
    parser.add_argument('--init_alpha', default=0.6, type=float, help='åˆå§‹æœ¬åœ°ä¸å…¨å±€æŸå¤±å¹³è¡¡å› å­')
    parser.add_argument('--min_alpha', default=0.4, type=float, help='æœ€å°æœ¬åœ°ä¸å…¨å±€æŸå¤±å¹³è¡¡å› å­')
    parser.add_argument('--init_lambda', default=0.15, type=float, help='åˆå§‹ç‰¹å¾å¯¹é½æŸå¤±æƒé‡')
    parser.add_argument('--beta', default=0.3, type=float, help='èšåˆåŠ¨é‡å› å­')
    
    # åˆ†å±‚é‡‡æ ·å‚æ•°
    parser.add_argument('--client_fraction', default=0.7, type=float, help='æ¯è½®å‚ä¸è®­ç»ƒçš„å®¢æˆ·ç«¯æ¯”ä¾‹(0-1)')
    parser.add_argument('--retier_interval', default=10, type=int, help='æ¯éš”å¤šå°‘è½®é‡æ–°åˆ†å±‚/èšç±»')
    parser.add_argument('--mu', default=0.0, type=float, help='FedProxæ­£åˆ™åŒ–ç³»æ•°(0è¡¨ç¤ºå…³é—­)')
    
    # è®­ç»ƒé˜¶æ®µå‚æ•°
    parser.add_argument('--initial_feature_rounds', default=5, type=int, help='åˆå§‹ç‰¹å¾å­¦ä¹ é˜¶æ®µè½®æ•°')
    parser.add_argument('--initial_phase_rounds', default=2, type=int, help='åˆå§‹é˜¶æ®µè½®æ•°')
    parser.add_argument('--alternating_phase_rounds', default=0, type=int, help='äº¤æ›¿è®­ç»ƒé˜¶æ®µè½®æ•°(0è¡¨ç¤ºè‡ªåŠ¨è®¡ç®—)')
    parser.add_argument('--fine_tuning_phase_rounds', default=0, type=int, help='ç²¾ç»†è°ƒæ•´é˜¶æ®µè½®æ•°')

    parser.add_argument('--use_offline_wandb', default=0, type=int, help='æ˜¯å¦ä½¿ç”¨ç¦»çº¿wandbè®°å½•(1è¡¨ç¤ºæ˜¯)')
    parser.add_argument('--log_tag', default='', type=str, help='æ—¥å¿—æ ‡ç­¾ï¼Œç”¨äºåŒºåˆ†ä¸åŒå®éªŒ')
    parser.add_argument('--target_accuracy', default=None, type=float, help='ç›®æ ‡ç²¾åº¦ï¼Œè¾¾åˆ°åç«‹å³åœæ­¢è®­ç»ƒ(å¦‚60.0è¡¨ç¤º60%)')
    parser.add_argument('--patience', default=15, type=int, help='æ—©åœè€å¿ƒå€¼ï¼Œè¿ç»­å¤šå°‘è½®æ— æ”¹å–„ååœæ­¢')

    parser.add_argument("--device", type=str, default="auto",
                    choices=["auto", "cuda", "cpu", "mps"],
                    help="auto ä¼˜å…ˆ cudaï¼Œå…¶æ¬¡ mpsï¼Œæœ€å cpu")
    parser.add_argument("--amp", action="store_true",
                        help="å¯ç”¨æ··åˆç²¾åº¦ï¼ˆä»…åœ¨ cuda æ—¶ç”Ÿæ•ˆï¼‰")
    parser.add_argument("--num_workers", type=int, default=4,
                        help="DataLoader çš„å·¥ä½œè¿›ç¨‹æ•°ï¼ˆKaggle æ¨è 2~4ï¼‰")
    
    # è®­ç»ƒé˜¶æ®µå‚æ•°
    parser.add_argument("--server_first_warmup", action="store_true",
                        help="åœ¨åˆå§‹é˜¶æ®µä¼˜å…ˆè®­ç»ƒæœåŠ¡å™¨æ¨¡å‹")
    parser.add_argument("--warmup_rounds", type=int, default=2,
                        help="é¢„çƒ­è½®æ•°")
    parser.add_argument("--disable_agg_rounds", type=int, default=0,
                        help="ç¦ç”¨èšåˆçš„è½®æ•°")

    
    args = parser.parse_args()
    return args

def setup_wandb(args):
    """ä»…è´Ÿè´£åˆå§‹åŒ– wandbï¼Œä¸å†åŠ¨ logging çš„ handlerã€‚"""
    logger = logging.getLogger("TierHFL")
    try:
        # ğŸ”¥ ä½¿ç”¨å‚æ•°æ§åˆ¶wandbæ¨¡å¼å’Œæ ‡ç­¾
        mode = "offline" if args.use_offline_wandb == 1 else "online"
        
        # æ„å»ºåŠ¨æ€æ ‡ç­¾
        tags = [f"model_{args.model}", f"dataset_{args.dataset}",
               f"clients_{args.client_number}", f"partition_{args.partition_method}"]
        if args.log_tag:
            tags.append(args.log_tag)
            
        wandb.init(
            mode=mode,
            project="TierHFL_Enhanced",
            name=args.running_name,
            config=vars(args),
            tags=tags,
            group=f"{args.model}_{args.dataset}"
        )
        # è‡ªå®šä¹‰é¢æ¿
        wandb.define_metric("round")
        wandb.define_metric("global/*", step_metric="round")
        wandb.define_metric("local/*", step_metric="round")
        wandb.define_metric("client/*", step_metric="round")
        wandb.define_metric("time/*", step_metric="round")
        wandb.define_metric("params/*", step_metric="round")
        logger.info(f"wandb åˆå§‹åŒ–å®Œæˆï¼ˆ{mode}ï¼‰ã€‚")
    except Exception as e:
        logger.warning(f"wandb åˆå§‹åŒ–å¤±è´¥: {e}")
        try:
            wandb.init(mode="offline", project="TierHFL", name=args.running_name)
            logger.info("å·²åˆ‡æ¢åˆ°ç®€åŒ–çš„ wandb åˆå§‹åŒ–ï¼ˆofflineï¼‰ã€‚")
        except Exception:
            logger.warning("å®Œå…¨ç¦ç”¨ wandbã€‚")


# --- Fallback: æœ¬åœ° Fashion-MNIST åˆ‡åˆ†ä¸ºå¤šä¸ªå®¢æˆ·ç«¯çš„ç®€å•å®ç° ---
def fallback_load_partition_data_fashion_mnist(dataset, data_dir, partition_method, partition_alpha,
                                              client_number, batch_size):
    import torchvision, torchvision.transforms as T
    from torch.utils.data import DataLoader, Subset
    import numpy as np

    # Kaggle æ— ç½‘æ—¶ä¸è¦ä¸‹è½½
    transform_train = T.Compose([T.RandomCrop(28, padding=2), T.ToTensor(), T.Normalize([0.2860],[0.3530])])
    transform_test  = T.Compose([T.ToTensor(), T.Normalize([0.2860],[0.3530])])

    # å°è¯•ä¸ä¸‹è½½ï¼›å¦‚æœ¬åœ°æ— æ•°æ®ä¼šæŠ›é”™ï¼Œå†æç¤ºç”¨ Kaggle Datasets
    try:
        trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=False, transform=transform_train)
        testset  = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=False, transform=transform_test)
    except Exception:
        raise RuntimeError("æœ¬åœ°æœªæ‰¾åˆ° Fashion-MNISTï¼ŒKaggle æ— ç½‘çŠ¶æ€è¯·å…ˆåœ¨å³ä¾§ 'Add data' æŒ‚è½½ Fashion-MNIST æ•°æ®é›†æˆ–æŠŠæ•°æ®æ‹·åˆ° ./data")

    n = len(trainset)
    idx = np.arange(n)
    np.random.shuffle(idx)
    # ç®€å•å‡åˆ†ç»™å„å®¢æˆ·ç«¯ï¼ˆhetero/alpha å¤æ‚åˆ‡åˆ†æ­¤å¤„å…ˆçœç•¥ï¼Œèƒ½è·‘ä¸ºå…ˆï¼‰
    splits = np.array_split(idx, client_number)

    train_data_local_dict, test_data_local_dict, train_data_local_num_dict = {}, {}, {}
    for cid in range(client_number):
        train_subset = Subset(trainset, splits[cid])
        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=False)
        test_loader  = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=False)
        train_data_local_dict[cid] = train_loader
        test_data_local_dict[cid] = test_loader
        train_data_local_num_dict[cid] = len(train_subset)

    train_data_num = len(trainset); test_data_num = len(testset); class_num = 10
    train_data_global = None; test_data_global = None
    return train_data_num, test_data_num, train_data_global, test_data_global, \
           train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num

def load_dataset(args):
    try:
        if args.dataset == "cifar10":
            from api.data_preprocessing.cifar10.data_loader import load_partition_data_cifar10
            data_loader = load_partition_data_cifar10
        elif args.dataset == "cifar100":
            from api.data_preprocessing.cifar100.data_loader import load_partition_data_cifar100
            data_loader = load_partition_data_cifar100
        elif args.dataset == "fashion_mnist":
            from api.data_preprocessing.fashion_mnist.data_loader import load_partition_data_fashion_mnist
            data_loader = load_partition_data_fashion_mnist
        elif args.dataset == "cinic10":
            from api.data_preprocessing.cinic10.data_loader import load_partition_data_cinic10
            data_loader = load_partition_data_cinic10
            args.data_dir = './data/cinic10/'
        else:
            from api.data_preprocessing.cifar10.data_loader import load_partition_data_cifar10
            data_loader = load_partition_data_cifar10

        if args.dataset == "cinic10":
            train_data_num, test_data_num, train_data_global, test_data_global, \
            train_data_local_num_dict, train_data_local_dict, test_data_local_dict, \
            class_num, traindata_cls_counts = data_loader(args.dataset, args.data_dir, args.partition_method,
                                    args.partition_alpha, args.client_number, args.batch_size)
            
            dataset = [train_data_num, test_data_num, train_data_global, test_data_global,
                       train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num, traindata_cls_counts]
            
        else:
            train_data_num, test_data_num, train_data_global, test_data_global, \
            train_data_local_num_dict, train_data_local_dict, test_data_local_dict, \
            class_num = data_loader(args.dataset, args.data_dir, args.partition_method,
                                    args.partition_alpha, args.client_number, args.batch_size)
            
            dataset = [train_data_num, test_data_num, train_data_global, test_data_global,
                       train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num]
    
    except Exception as e:
        print(f"[WARN] æ­£å¼æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ fallbackï¼š{e}")
        if args.dataset == "fashion_mnist":
            train_data_num, test_data_num, train_data_global, test_data_global, \
            train_data_local_num_dict, train_data_local_dict, test_data_local_dict, \
            class_num = fallback_load_partition_data_fashion_mnist(args.dataset, args.data_dir, args.partition_method,
                                    args.partition_alpha, args.client_number, args.batch_size)
            
            dataset = [train_data_num, test_data_num, train_data_global, test_data_global,
                       train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num]
        else:
            raise
    
    return dataset

def allocate_device_resources(client_number):
    resources = {}
    
    # éšæœºåˆ†é…tier (1-4)
    tier_weights = [0.2, 0.3, 0.3, 0.2]  # tier 1-4çš„åˆ†å¸ƒæ¦‚ç‡
    tiers = random.choices(range(1, 5), weights=tier_weights, k=client_number)
    
    # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯åˆ†é…èµ„æº
    for client_id in range(client_number):
        tier = tiers[client_id]
        
        # æ ¹æ®tieråˆ†é…è®¡ç®—èƒ½åŠ›
        if tier == 1:  # é«˜æ€§èƒ½è®¾å¤‡
            compute_power = random.uniform(0.8, 1.0)
            network_speed = random.choice([50, 100, 200])
            storage_capacity = random.choice([256, 512, 1024])
        elif tier == 2:  # ä¸­é«˜æ€§èƒ½è®¾å¤‡
            compute_power = random.uniform(0.6, 0.8)
            network_speed = random.choice([30, 50, 100])
            storage_capacity = random.choice([128, 256, 512])
        elif tier == 3:  # ä¸­ä½æ€§èƒ½è®¾å¤‡
            compute_power = random.uniform(0.3, 0.6)
            network_speed = random.choice([20, 30, 50])
            storage_capacity = random.choice([64, 128, 256])
        else:  # tier 4, ä½æ€§èƒ½è®¾å¤‡
            compute_power = random.uniform(0.1, 0.3)
            network_speed = random.choice([5, 10, 20])
            storage_capacity = random.choice([16, 32, 64])
        
        # å­˜å‚¨èµ„æºä¿¡æ¯
        resources[client_id] = {
            "tier": tier,
            "compute_power": compute_power,
            "network_speed": network_speed,
            "storage_capacity": storage_capacity
        }
    
    return resources

def print_cluster_info(cluster_map, client_resources, logger):
    """æ‰“å°èšç±»ä¿¡æ¯è¯¦æƒ…"""
    logger.info("===== èšç±»åˆ†å¸ƒæƒ…å†µ =====")
    for cluster_id, client_ids in cluster_map.items():
        client_tiers = [client_resources[client_id]['tier'] for client_id in client_ids]
        avg_tier = sum(client_tiers) / len(client_tiers) if client_tiers else 0
        tier_distribution = {}
        for tier in client_tiers:
            tier_distribution[tier] = tier_distribution.get(tier, 0) + 1
            
        logger.info(f"èšç±» {cluster_id}: {len(client_ids)}ä¸ªå®¢æˆ·ç«¯")
        logger.info(f"  - å®¢æˆ·ç«¯ID: {client_ids}")
        logger.info(f"  - å¹³å‡Tier: {avg_tier:.2f}")
        logger.info(f"  - Tieråˆ†å¸ƒ: {tier_distribution}")
        
        # è®¡ç®—å®¢æˆ·ç«¯èµ„æºå¼‚è´¨æ€§
        if client_ids:
            compute_powers = [client_resources[cid]['compute_power'] for cid in client_ids]
            network_speeds = [client_resources[cid]['network_speed'] for cid in client_ids]
            
            logger.info(f"  - è®¡ç®—èƒ½åŠ›: å¹³å‡={sum(compute_powers)/len(compute_powers):.2f}, "
                       f"æœ€å°={min(compute_powers):.2f}, æœ€å¤§={max(compute_powers):.2f}")
            logger.info(f"  - ç½‘ç»œé€Ÿåº¦: å¹³å‡={sum(network_speeds)/len(network_speeds):.2f}, "
                       f"æœ€å°={min(network_speeds)}, æœ€å¤§={max(network_speeds)}")
    
    # è®¡ç®—å…¨å±€èšç±»æŒ‡æ ‡
    all_clients = sum(len(clients) for clients in cluster_map.values())
    logger.info(f"æ€»è®¡: {len(cluster_map)}ä¸ªèšç±», {all_clients}ä¸ªå®¢æˆ·ç«¯")

def load_global_test_set(args):
    """åˆ›å»ºå…¨å±€IIDæµ‹è¯•é›†ç”¨äºè¯„ä¼°æ³›åŒ–æ€§èƒ½"""
    if args.dataset == "cifar10":
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.49139968, 0.48215827, 0.44653124], 
                                [0.24703233, 0.24348505, 0.26158768])
        ])
        
        testset = torchvision.datasets.CIFAR10(
            root=args.data_dir, train=False, download=True, transform=transform_test)
        test_loader = torch.utils.data.DataLoader(
            testset, batch_size=args.batch_size, shuffle=False, num_workers=2)
        
        return test_loader
    
    elif args.dataset == "cifar100":
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.5071, 0.4867, 0.4408],
                                [0.2675, 0.2565, 0.2761])
        ])
        
        testset = torchvision.datasets.CIFAR100(
            root=args.data_dir, train=False, download=True, transform=transform_test)
        test_loader = torch.utils.data.DataLoader(
            testset, batch_size=args.batch_size, shuffle=False, num_workers=2)
        
        return test_loader
    
    elif args.dataset == "fashion_mnist":
        # æ–°å¢Fashion-MNISTæ”¯æŒ
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.2860], [0.3530])
        ])
        
        testset = torchvision.datasets.FashionMNIST(
            root=args.data_dir, train=False, download=True, transform=transform_test)
        test_loader = torch.utils.data.DataLoader(
            testset, batch_size=args.batch_size, shuffle=False, num_workers=2)
        
        return test_loader
    
    elif args.dataset == "cinic10":
        transform_test = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.47889522, 0.47227842, 0.43047404],
                                [0.24205776, 0.23828046, 0.25874835])
        ])
        
        # ä½¿ç”¨å­˜å‚¨åœ¨args.data_dir/cinic10/testç›®å½•ä¸‹çš„CINIC10æµ‹è¯•é›†
        testset = torchvision.datasets.ImageFolder(
            root=os.path.join(args.data_dir, 'cinic10', 'test'),
            transform=transform_test)
        test_loader = torch.utils.data.DataLoader(
            testset, batch_size=args.batch_size, shuffle=False, num_workers=2)
        
        return test_loader
    else:
        # é»˜è®¤è¿”å›CIFAR10
        raise ValueError(f"Unsupported dataset: {args.dataset}")

def evaluate_global_model_multi_client(client_models, server_model, global_classifier, global_test_loader, device, num_eval_clients=3):
    """ğŸ”¥ ä½¿ç”¨å¤šä¸ªå®¢æˆ·ç«¯è¿›è¡Œå…¨å±€æ¨¡å‹è¯„ä¼°ï¼Œæé«˜è¯„ä¼°ç¨³å¥æ€§"""
    # éšæœºé€‰æ‹©å¤šä¸ªå®¢æˆ·ç«¯è¿›è¡Œè¯„ä¼°ï¼Œé¿å…å›ºå®šé€‰æ‹©å‰å‡ ä¸ªé€ æˆåå·®
    client_ids = list(client_models.keys())
    
    if len(client_ids) <= num_eval_clients:
        eval_client_ids = client_ids  # å¦‚æœå®¢æˆ·ç«¯æ•°é‡ä¸å¤šï¼Œå…¨éƒ¨è¯„ä¼°
    else:
        # éšæœºé‡‡æ ·ï¼Œç¡®ä¿è¯„ä¼°çš„å¤šæ ·æ€§
        import random
        eval_client_ids = random.sample(client_ids, num_eval_clients)
    
    all_accuracies = []
    
    for client_id in eval_client_ids:
        client_model = client_models[client_id]
        accuracy = evaluate_global_model(client_model, server_model, global_classifier, global_test_loader, device)
        all_accuracies.append(accuracy)
        print(f"ğŸ“ˆ å®¢æˆ·ç«¯{client_id}è¯„ä¼°å‡†ç¡®ç‡: {accuracy:.2f}%")
    
    # è¿”å›å¹³å‡å‡†ç¡®ç‡
    avg_accuracy = sum(all_accuracies) / len(all_accuracies)
    print(f"ğŸ“ˆ å¤šå®¢æˆ·ç«¯å¹³å‡è¯„ä¼°å‡†ç¡®ç‡: {avg_accuracy:.2f}%")
    
    return avg_accuracy

def evaluate_global_model(client_model, server_model, global_classifier, global_test_loader, device):
    """è¯„ä¼°å…¨å±€æ¨¡å‹åœ¨å…¨å±€æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½ - ä¿®å¤ç‰ˆ"""
    # ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
    client_model = client_model.to(device)
    server_model = server_model.to(device)
    global_classifier = global_classifier.to(device)
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    client_model.eval()
    server_model.eval()
    global_classifier.eval()
    
    correct = 0
    total = 0
    all_predictions = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in global_test_loader:
            # ç§»åˆ°è®¾å¤‡
            data, target = data.to(device), target.to(device)
            
            try:
                # å®Œæ•´çš„å‰å‘ä¼ æ’­
                _, shared_features, _ = client_model(data)
                server_features = server_model(shared_features)
                logits = global_classifier(server_features)
                
                _, predicted = logits.max(1)
                total += target.size(0)
                correct += predicted.eq(target).sum().item()
                
                # è®°å½•é¢„æµ‹å’Œç›®æ ‡ï¼Œç”¨äºåç»­åˆ†æ
                all_predictions.extend(predicted.cpu().numpy())
                all_targets.extend(target.cpu().numpy())
            except Exception as e:
                print(f"è¯„ä¼°ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                continue
    
    accuracy = 100.0 * correct / max(1, total)
    
    return accuracy

class ModelFeatureClusterer:
    def __init__(self, num_clusters=3):
        self.num_clusters = num_clusters
        self.clustering_history = []
    
    def cluster_clients(self, client_models, client_ids, eval_dataset=None, device='cuda'):
        """åŸºäºæ¨¡å‹ç‰¹å¾çš„èšç±»æ–¹æ³•ï¼Œè€ƒè™‘æœåŠ¡å™¨ä¸èƒ½è·å–åŸå§‹æ•°æ®çš„é™åˆ¶"""
        clusters = {i: [] for i in range(self.num_clusters)}
        
        # æå–æ¨¡å‹ç‰¹å¾ - ä½¿ç”¨å…±äº«å±‚å‚æ•°è€ŒéåŸå§‹æ•°æ®
        client_features = {}
        feature_dims = []
        
        # ç¬¬ä¸€æ­¥ï¼šæå–ç‰¹å¾
        for client_id in client_ids:
            if client_id in client_models:
                model = client_models[client_id]
                features = []
                
                # åªæå–å…±äº«å±‚å‚æ•°ä½œä¸ºç‰¹å¾
                for name, param in model.named_parameters():
                    if 'shared_base' in name and 'weight' in name:
                        # æå–ç»Ÿè®¡ä¿¡æ¯è€ŒéåŸå§‹å‚æ•°
                        param_data = param.detach().cpu()
                        # åªæ”¶é›†æ ‡é‡ç‰¹å¾ï¼Œé¿å…å½¢çŠ¶ä¸ä¸€è‡´
                        features.extend([
                            param_data.mean().item(),
                            param_data.std().item(),
                            param_data.abs().max().item(),
                            (param_data > 0).float().mean().item()  # æ­£å€¼æ¯”ä¾‹
                        ])
                
                if features:
                    # ç¡®ä¿featuresæ˜¯ä¸€ç»´æ•°ç»„
                    features_array = np.array(features, dtype=np.float32)
                    client_features[client_id] = features_array
                    feature_dims.append(len(features_array))
        
        # æ£€æŸ¥æ‰€æœ‰ç‰¹å¾å‘é‡çš„ç»´åº¦æ˜¯å¦ä¸€è‡´
        if feature_dims and len(set(feature_dims)) > 1:
            # å¦‚æœç»´åº¦ä¸ä¸€è‡´ï¼Œæ‰¾å‡ºæœ€å¸¸è§çš„ç»´åº¦
            from collections import Counter
            dim_counter = Counter(feature_dims)
            common_dim = dim_counter.most_common(1)[0][0]
            
            print(f"å‘ç°ä¸åŒç»´åº¦çš„ç‰¹å¾å‘é‡: {dict(dim_counter)}ï¼Œä½¿ç”¨æœ€å¸¸è§ç»´åº¦: {common_dim}")
            
            # å¤„ç†ç»´åº¦ä¸ä¸€è‡´çš„ç‰¹å¾å‘é‡
            for client_id in list(client_features.keys()):
                feat = client_features[client_id]
                if len(feat) != common_dim:
                    if len(feat) < common_dim:
                        # å¦‚æœç‰¹å¾å¤ªçŸ­ï¼Œä½¿ç”¨å¡«å……
                        client_features[client_id] = np.pad(feat, (0, common_dim - len(feat)), 'constant')
                    else:
                        # å¦‚æœç‰¹å¾å¤ªé•¿ï¼Œè¿›è¡Œè£å‰ª
                        client_features[client_id] = feat[:common_dim]
        
        # å°è¯•K-meansèšç±»
        if len(client_features) >= self.num_clusters:
            try:
                from sklearn.cluster import KMeans
                # è½¬æ¢ä¸ºçŸ©é˜µ
                feature_client_ids = list(client_features.keys())
                features_matrix = np.vstack([client_features[cid] for cid in feature_client_ids])
                
                # æ ‡å‡†åŒ–ç‰¹å¾
                mean = np.mean(features_matrix, axis=0)
                std = np.std(features_matrix, axis=0) + 1e-8
                features_matrix = (features_matrix - mean) / std
                
                # æ‰§è¡ŒK-means
                kmeans = KMeans(n_clusters=self.num_clusters, random_state=42, n_init=10)
                kmeans.fit(features_matrix)
                
                # æ„å»ºèšç±»æ˜ å°„
                for i, label in enumerate(kmeans.labels_):
                    client_id = feature_client_ids[i]
                    clusters[label].append(client_id)
                
                # å¤„ç†æ²¡æœ‰ç‰¹å¾çš„å®¢æˆ·ç«¯ - å¹³å‡åˆ†é…
                remaining_clients = [cid for cid in client_ids if cid not in client_features]
                for i, client_id in enumerate(remaining_clients):
                    target_cluster = i % self.num_clusters
                    clusters[target_cluster].append(client_id)
                    
            except Exception as e:
                print(f"K-meansèšç±»å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ")
                # å¤‡ç”¨æ–¹æ¡ˆ - å‡åŒ€åˆ†é…
                for i, client_id in enumerate(client_ids):
                    cluster_idx = i % self.num_clusters
                    clusters[cluster_idx].append(client_id)
        else:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šå‡åŒ€åˆ†é…
            for i, client_id in enumerate(client_ids):
                cluster_idx = i % self.num_clusters
                clusters[cluster_idx].append(client_id)
        
        # è®°å½•èšç±»ç»“æœ
        self.clustering_history.append({
            'timestamp': time.time(),
            'clusters': copy.deepcopy(clusters),
            'num_clients': len(client_ids)
        })
            
        return clusters

# ä¸»å‡½æ•°
def main():
    """ä¸»å‡½æ•°ï¼šå¢å¼ºç‰ˆTierHFLå®ç°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parse_arguments()

    # ğŸ”¥ è®­ç»ƒé˜¶æ®µè½®æ•°è‡ªåŠ¨è®¡ç®—ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
    if args.alternating_phase_rounds == 0:
        args.alternating_phase_rounds = args.rounds - args.initial_phase_rounds - args.fine_tuning_phase_rounds
        args.alternating_phase_rounds = max(1, args.alternating_phase_rounds)  # ç¡®ä¿è‡³å°‘1è½®

    log_file = setup_logging(run_name=getattr(args, "running_name", "run"))

    import logging
    logger = logging.getLogger("TierHFL")
    setup_wandb(args)

    logger.info("åˆå§‹åŒ–TierHFL: å¢å¼ºç‰ˆæœ¬ - é›†æˆæ¢¯åº¦æŠ•å½±å’Œåˆ†å±‚èšåˆ")

    # è®¾å¤‡
    if args.device == "auto":
        if torch.cuda.is_available():
            device = torch.device("cuda")
        elif getattr(torch.backends, "mps", None) and torch.backends.mps.is_available():
            device = torch.device("mps")
        else:
            device = torch.device("cpu")
    else:
        device = torch.device(args.device)

    if device.type == "cuda":
        torch.backends.cudnn.benchmark = True  # æå‡å·ç§¯æ€§èƒ½
    logging.info(f"ä½¿ç”¨è®¾å¤‡: {device}")

    pin_mem = (str(device) == "cuda")

    
    # åŠ è½½æ•°æ®é›†
    logger.info(f"åŠ è½½æ•°æ®é›†: {args.dataset}")
    dataset = load_dataset(args)
    
    # è·å–æ•°æ®é›†ä¿¡æ¯
    if args.dataset != "cinic10":
        train_data_num, test_data_num, _, _, train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num = dataset
    else:
        train_data_num, test_data_num, _, _, train_data_local_num_dict, train_data_local_dict, test_data_local_dict, class_num, _ = dataset
    
    # åŠ è½½å…¨å±€æµ‹è¯•é›†
    logger.info("åŠ è½½å…¨å±€IIDæµ‹è¯•é›†ç”¨äºè¯„ä¼°æ³›åŒ–æ€§èƒ½...")
    global_test_loader = load_global_test_set(args)
    
    # åˆ†é…å®¢æˆ·ç«¯èµ„æº
    logger.info(f"ä¸º {args.client_number} ä¸ªå®¢æˆ·ç«¯åˆ†é…å¼‚æ„èµ„æº...")
    client_resources = allocate_device_resources(args.client_number)
    
    # åˆ›å»ºå®¢æˆ·ç«¯ç®¡ç†å™¨
    logger.info("åˆ›å»ºå®¢æˆ·ç«¯ç®¡ç†å™¨...")
    client_manager = TierHFLClientManager()
    
    # === [MARK-CLIENT-DATALOADERS] æ¯ä¸ªå®¢æˆ·ç«¯å…ˆå»º DataLoader å†æ³¨å†Œ ===
    from torch.utils.data import DataLoader

    for client_id in range(args.client_number):
        resource = client_resources[client_id]
        tier = resource["tier"]

        # 1) ç›´æ¥ä½¿ç”¨é¢„å¤„ç†å¥½çš„ DataLoaderï¼ˆå·²ç»åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µåˆ›å»ºï¼‰
        train_loader = train_data_local_dict[client_id]
        test_loader = test_data_local_dict[client_id]

        # 2) æŠŠ DataLoader ä¼ ç»™å®¢æˆ·ç«¯ç®¡ç†å™¨
        client = client_manager.add_client(
            client_id=client_id,
            tier=tier,
            train_data=train_loader,
            test_data=test_loader,
            device=device,
            lr=args.lr,
            local_epochs=args.client_epoch
        )
        client.wd = args.wd
    # === [MARK-CLIENT-DATALOADERS] END ===



    # ç¡®å®šè¾“å…¥é€šé“æ•°
    input_channels = 1 if args.dataset == "fashion_mnist" else 3

    # åˆ›å»ºå®¢æˆ·ç«¯æ¨¡å‹
    logger.info("åˆ›å»ºåŒè·¯å¾„å®¢æˆ·ç«¯æ¨¡å‹...")
    client_models = {}
    for client_id, resource in client_resources.items():
        client_models[client_id] = TierAwareClientModel(
            num_classes=class_num,
            input_channels=(1 if args.dataset in ["mnist", "fashion_mnist"] else 3)
        )
        
    # åˆ›å»ºæœåŠ¡å™¨ç‰¹å¾æå–æ¨¡å‹
    logger.info("åˆ›å»ºæœåŠ¡å™¨ç‰¹å¾æå–æ¨¡å‹...")
    server_model = EnhancedServerModel(
        model_type=args.model,
        feature_dim=384,  # ğŸ”¥ ä»256æå‡åˆ°384ï¼Œè¿›ä¸€æ­¥æå‡CIFAR-100è¡¨å¾èƒ½åŠ›
        input_channels=input_channels  # æ·»åŠ è¾“å…¥é€šé“å‚æ•°
    ).to(device)
    
    # åˆ›å»ºå…¨å±€åˆ†ç±»å™¨
    logger.info("åˆ›å»ºå…¨å±€åˆ†ç±»å™¨...")
    global_classifier = ImprovedGlobalClassifier(
        feature_dim=384,  # ğŸ”¥ ä»256æå‡åˆ°384ï¼ŒåŒ¹é…æœåŠ¡å™¨ç‰¹å¾ç»´åº¦
        num_classes=class_num
    ).to(device)
    
    # åˆ›å»ºå®¢æˆ·ç«¯èšç±»å™¨
    logger.info("åˆ›å»ºæ•°æ®åˆ†å¸ƒèšç±»å™¨...")
    clusterer = ModelFeatureClusterer(num_clusters=args.n_clusters)
    
    # å¯¹å®¢æˆ·ç«¯è¿›è¡Œåˆå§‹èšç±»
    logger.info("æ‰§è¡Œåˆå§‹å®¢æˆ·ç«¯èšç±»...")
    client_ids = list(range(args.client_number))
    cluster_map = clusterer.cluster_clients(
        client_models=client_models,
        client_ids=client_ids
    )
    
    # æ‰“å°åˆå§‹èšç±»ä¿¡æ¯
    print_cluster_info(cluster_map, client_resources, logger)
    
    # åˆ›å»ºå¢å¼ºç‰ˆä¸²è¡Œè®­ç»ƒå™¨
    logger.info("åˆ›å»ºå¢å¼ºç‰ˆä¸²è¡Œè®­ç»ƒå™¨...")
    trainer = EnhancedSerialTrainer(
        client_manager=client_manager,
        server_model=server_model,
        global_classifier=global_classifier,
        device=str(device),
        use_amp=args.amp
    )
    
    # ğŸ”¥ è®¾ç½®FedProxæ­£åˆ™åŒ–ç³»æ•°
    trainer.mu = args.mu

    
    # æ³¨å†Œå®¢æˆ·ç«¯æ¨¡å‹
    trainer.register_client_models(client_models)
    
    # è®¾ç½®è®­ç»ƒç¯å¢ƒ
    trainer.setup_training(cluster_map=cluster_map)

    # åˆ›å»ºè¯Šæ–­ç›‘æ§å™¨
    logger.info("åˆ›å»ºè¯Šæ–­ç›‘æ§å™¨...")
    diagnostic_monitor = EnhancedTierHFLDiagnosticMonitor(device='cpu')
    
    # ğŸ”¥ åˆ›å»ºå…¨å±€å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆè·¨è½®Cosineè°ƒåº¦ï¼‰
    # æ”¶é›†æœåŠ¡å™¨æ¨¡å‹å’Œå…¨å±€åˆ†ç±»å™¨çš„å‚æ•°ç”¨äºå…¨å±€è°ƒåº¦
    global_params = list(server_model.parameters()) + list(global_classifier.parameters())
    global_optimizer = torch.optim.SGD(
        global_params, lr=args.lr, momentum=0.9, weight_decay=5e-4, nesterov=True
    )
    
    # Cosineå­¦ä¹ ç‡è°ƒåº¦ï¼Œå¸¦5è½®warmup
    def cosine_lr_with_warmup(optimizer, current_round, total_rounds, warmup_rounds=5, eta_min=1e-4):
        if current_round < warmup_rounds:
            # Warmupé˜¶æ®µï¼šçº¿æ€§å¢é•¿åˆ°åˆå§‹å­¦ä¹ ç‡
            lr_factor = (current_round + 1) / warmup_rounds
        else:
            # Cosineé€€ç«é˜¶æ®µ
            progress = (current_round - warmup_rounds) / (total_rounds - warmup_rounds)
            lr_factor = 0.5 * (1 + np.cos(np.pi * progress))
            lr_factor = max(lr_factor, eta_min / args.lr)  # ç¡®ä¿ä¸ä½äºeta_min
        
        for param_group in optimizer.param_groups:
            param_group['lr'] = args.lr * lr_factor
        
        return args.lr * lr_factor
    
    # å¼€å§‹è®­ç»ƒå¾ªç¯
    logger.info(f"å¼€å§‹è”é‚¦å­¦ä¹ è®­ç»ƒ ({args.rounds} è½®)...")
    best_accuracy = 0.0
    prev_global_acc = 0.0
    
    # ğŸ”¥ æ—©åœå‚æ•°
    patience = args.patience  # ä½¿ç”¨å‚æ•°é…ç½®çš„è€å¿ƒå€¼
    best_round = 0
    no_improve_count = 0
    target_accuracy = args.target_accuracy  # ç›®æ ‡ç²¾åº¦
    
    # åœ¨è®­ç»ƒå¼€å§‹å‰è¿›è¡Œåˆå§‹éªŒè¯
    initial_validation = validate_server_effectiveness(
        args, 
        client_models,
        server_model, 
        global_classifier,
        global_test_loader, 
        test_data_local_dict,
        device='cpu'
    )

    for round_idx in range(args.rounds):
        round_start_time = time.time()
        logger.info(f"===== è½®æ¬¡ {round_idx+1}/{args.rounds} =====")
        
        # æ·»åŠ è®­ç»ƒé˜¶æ®µä¿¡æ¯
        if round_idx < args.initial_phase_rounds:
            logger.info("å½“å‰å¤„äºåˆå§‹ç‰¹å¾å­¦ä¹ é˜¶æ®µ")
        elif round_idx < args.initial_phase_rounds + args.alternating_phase_rounds:
            logger.info("å½“å‰å¤„äºäº¤æ›¿è®­ç»ƒé˜¶æ®µ")
        else:
            logger.info("å½“å‰å¤„äºç²¾ç»†è°ƒæ•´é˜¶æ®µ")
        
        # æ‰§è¡Œè®­ç»ƒ - ä¼ é€’å¢å¼ºç‰ˆè¯Šæ–­ç›‘æ§å™¨
        train_results, eval_results, shared_states, training_time = trainer.execute_round(
            round_idx=round_idx, 
            total_rounds=args.rounds,
            args=args,
            diagnostic_monitor=diagnostic_monitor
        )
        
        # èšåˆè¿‡ç¨‹
        logger.info("ä½¿ç”¨åˆ†å±‚èšåˆç­–ç•¥èšåˆæ¨¡å‹...")
        aggregation_start_time = time.time()
        
        # èšåˆå®¢æˆ·ç«¯å…±äº«å±‚
        aggregated_shared_state = trainer.aggregate_client_shared_layers(shared_states, eval_results)
        
        # èšåˆæœåŠ¡å™¨æ¨¡å‹
        aggregated_server_model = trainer.aggregate_server_models(eval_results)

        # èšåˆå…¨å±€åˆ†ç±»å™¨
        aggregated_global_classifier = trainer.aggregate_global_classifiers(eval_results)
        
        # æ›´æ–°æ¨¡å‹
        logger.info("æ›´æ–°å®¢æˆ·ç«¯å…±äº«å±‚...")
        trainer.update_client_shared_layers(aggregated_shared_state)
        
        logger.info("æ›´æ–°æœåŠ¡å™¨æ¨¡å‹...")
        trainer.update_server_models(aggregated_server_model, aggregated_global_classifier)
        
        aggregation_time = time.time() - aggregation_start_time
        
        # ğŸ”¥ ä¼˜åŒ–ï¼šä½¿ç”¨å¤šå®¢æˆ·ç«¯è¯„ä¼°å…¨å±€æ¨¡å‹ï¼Œæé«˜è¯„ä¼°ç¨³å¥æ€§
        global_model_accuracy = evaluate_global_model_multi_client(
            client_models, server_model, global_classifier, 
            global_test_loader, device, num_eval_clients=3)
        
        # è®¡ç®—å¹³å‡å‡†ç¡®ç‡
        avg_local_acc = np.mean([result.get('local_accuracy', 0) for result in eval_results.values()])
        avg_global_acc = np.mean([result.get('global_accuracy', 0) for result in eval_results.values()])
        
        # é€‰æ‹©ä¸€ä¸ªç”¨äºä¿å­˜çš„æ ·ä¾‹å®¢æˆ·ç«¯
        tier1_clients = [cid for cid, resource in client_resources.items() if resource.get("tier", 2) == 1]
        if len(tier1_clients) > 0:
            sample_client_id = int(tier1_clients[0])
        else:
            # å…œåº•ï¼šéšä¾¿æ‹¿ä¸€ä¸ªå­˜åœ¨çš„å®¢æˆ·ç«¯ID
            sample_client_id = int(list(client_models.keys())[0])
        
        # æ›´æ–°æœ€ä½³å‡†ç¡®ç‡
        is_best = global_model_accuracy > best_accuracy
        if is_best:
            best_accuracy = global_model_accuracy
            try:
                torch.save({
                    'client_model': client_models[sample_client_id].state_dict(),
                    'server_model': server_model.state_dict(),
                    'global_classifier': global_classifier.state_dict(),
                    'round': round_idx,
                    'accuracy': best_accuracy
                }, f"{args.running_name}_best_model.pth")
                logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {best_accuracy:.2f}%")
            except Exception as e:
                logger.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {str(e)}")
        
        # ğŸ”¥ è¾¾æ ‡å³åœæ£€æŸ¥
        if target_accuracy is not None and global_model_accuracy >= target_accuracy:
            logger.info(f"è¾¾åˆ°ç›®æ ‡ç²¾åº¦ {target_accuracy:.1f}%! å½“å‰ç²¾åº¦: {global_model_accuracy:.2f}% (è½®æ¬¡ {round_idx+1})")
            logger.info(f"æå‰åœæ­¢è®­ç»ƒï¼Œæœ€ä½³ç²¾åº¦: {best_accuracy:.2f}%")
            break
        
        # ğŸ”¥ æ—©åœæ£€æŸ¥
        if global_model_accuracy > best_accuracy + 1e-4:  # å¦‚æœæœ‰æ˜¾è‘—æ”¹å–„
            best_accuracy = global_model_accuracy
            best_round = round_idx
            no_improve_count = 0
            logger.info(f"æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}% (è½®æ¬¡ {round_idx+1})")
        else:
            no_improve_count += 1
            logger.info(f"æ— æ”¹å–„è®¡æ•°: {no_improve_count}/{patience}")
        
        # åˆ¤æ–­æ˜¯å¦éœ€è¦æ—©åœ
        if no_improve_count >= patience:
            logger.info(f"æ—©åœè§¦å‘! å·²è¿ç»­{patience}è½®æ— æ”¹å–„")
            logger.info(f"æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}% (è½®æ¬¡ {best_round+1})")
            break
        
        # è®¡ç®—è½®æ¬¡æ—¶é—´
        round_time = time.time() - round_start_time
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        logger.info(f"è½®æ¬¡ {round_idx+1} ç»Ÿè®¡:")
        logger.info(f"æœ¬åœ°å¹³å‡å‡†ç¡®ç‡: {avg_local_acc:.2f}%, å…¨å±€å¹³å‡å‡†ç¡®ç‡: {avg_global_acc:.2f}%")
        logger.info(f"å…¨å±€æ¨¡å‹åœ¨ç‹¬ç«‹æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡: {global_model_accuracy:.2f}%")
        logger.info(f"æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
        logger.info(f"è½®æ¬¡æ€»æ—¶é—´: {round_time:.2f}ç§’, è®­ç»ƒ: {training_time:.2f}ç§’, èšåˆ: {aggregation_time:.2f}ç§’")
        
        # è®°å½•å‡†ç¡®ç‡å˜åŒ–
        acc_change = global_model_accuracy - prev_global_acc
        prev_global_acc = global_model_accuracy
        logger.info(f"å…¨å±€å‡†ç¡®ç‡å˜åŒ–: {acc_change:.2f}%")
        
        # === å¢å¼ºç‰ˆè¯Šæ–­æŠ¥å‘Š ===
        if round_idx % 3 == 0:  # æ¯3è½®ç”Ÿæˆä¸€æ¬¡è¯¦ç»†æŠ¥å‘Š
            logger.info("=== å¢å¼ºç‰ˆè¯Šæ–­æŠ¥å‘Š ===")
            comprehensive_report = diagnostic_monitor.comprehensive_diagnostic_report(round_idx)
            
            logger.info(f"ç³»ç»Ÿå¥åº·çŠ¶æ€: {comprehensive_report['overall_health'].upper()}")
            
            if comprehensive_report['critical_issues']:
                logger.error("ä¸¥é‡é—®é¢˜:")
                for issue in comprehensive_report['critical_issues']:
                    logger.error(f"  ğŸš¨ {issue}")
            
            if comprehensive_report['warnings']:
                logger.warning("è­¦å‘Š:")
                for warning in comprehensive_report['warnings']:
                    logger.warning(f"  âš ï¸ {warning}")
            
            if comprehensive_report['recommendations']:
                logger.info("ä¼˜åŒ–å»ºè®®:")
                for rec in comprehensive_report['recommendations']:
                    logger.info(f"  ğŸ’¡ {rec}")
        
        # å¯¼å‡ºå¢å¼ºç‰ˆè¯Šæ–­æŒ‡æ ‡åˆ°wandb
        try:
            diagnostic_monitor.export_metrics_to_wandb(wandb)
        except Exception as e:
            logger.error(f"å¯¼å‡ºå¢å¼ºè¯Šæ–­æŒ‡æ ‡å¤±è´¥: {str(e)}")
        
        # è®°å½•åˆ°wandbï¼ˆæ·»åŠ å¥åº·çŠ¶æ€æŒ‡æ ‡ï¼‰
        try:
            # è·å–å½“å‰å¥åº·çŠ¶æ€
            current_report = diagnostic_monitor.comprehensive_diagnostic_report(round_idx)
            health_score = {'good': 1.0, 'warning': 0.7, 'poor': 0.4, 'critical': 0.0, 'error': 0.0}.get(
                current_report['overall_health'], 0.5)
            
            metrics = {
                "round": round_idx + 1,
                "global/test_accuracy": global_model_accuracy,
                "global/best_accuracy": best_accuracy,
                "local/avg_accuracy": avg_local_acc,
                "global/avg_accuracy": avg_global_acc,
                "time/round_seconds": round_time,
                "time/training_seconds": training_time,
                "time/aggregation_seconds": aggregation_time,
                "global/accuracy_change": acc_change,
                "diagnostic/system_health_score": health_score,
                "training/phase": 1 if round_idx < args.initial_phase_rounds else 
                                (2 if round_idx < args.initial_phase_rounds + args.alternating_phase_rounds else 3)
            }
            
            # æ·»åŠ ç‰¹å¾å¹³è¡¡å’ŒæŸå¤±ç»„ä»¶æŒ‡æ ‡
            if train_results:
                avg_balance_loss = np.mean([result.get('balance_loss', 0) for result in train_results.values()])
                metrics["training/avg_balance_loss"] = avg_balance_loss
            
            wandb.log(metrics)
        except Exception as e:
            logger.error(f"è®°å½•wandbæŒ‡æ ‡å¤±è´¥: {str(e)}")
        
        # ğŸ”¥ ä½¿ç”¨å‚æ•°æ§åˆ¶çš„é‡æ–°èšç±»é—´éš”
        if (round_idx + 1) % args.retier_interval == 0 and round_idx >= args.initial_phase_rounds:
            logger.info(f"é‡æ–°è¿›è¡Œå®¢æˆ·ç«¯èšç±»ï¼ˆé—´éš”ï¼š{args.retier_interval}è½®ï¼‰...")
            try:
                cluster_map = clusterer.cluster_clients(
                    client_models=client_models,
                    client_ids=client_ids,
                    eval_dataset=global_test_loader
                )
                trainer.setup_training(cluster_map=cluster_map)
                print_cluster_info(cluster_map, client_resources, logger)
            except Exception as e:
                logger.error(f"é‡æ–°èšç±»å¤±è´¥: {str(e)}")
        
        # ğŸ”¥ å…¨å±€Cosineå­¦ä¹ ç‡è°ƒåº¦
        current_global_lr = cosine_lr_with_warmup(
            global_optimizer, round_idx, args.rounds, warmup_rounds=5, eta_min=1e-4
        )
        
        # åŒæ­¥å®¢æˆ·ç«¯å­¦ä¹ ç‡ï¼ˆå¯é€‰æ‹©æ€§åœ°è®¾ç½®ä¸ºå…¨å±€å­¦ä¹ ç‡çš„ä¸€å®šæ¯”ä¾‹ï¼‰
        client_lr_ratio = 1.0  # å®¢æˆ·ç«¯ä¸å…¨å±€å­¦ä¹ ç‡çš„æ¯”ä¾‹
        for client_id in range(args.client_number):
            client = client_manager.get_client(client_id)
            if client:
                client.lr = current_global_lr * client_lr_ratio
        
        if round_idx % 10 == 0:  # æ¯10è½®è®°å½•ä¸€æ¬¡å­¦ä¹ ç‡
            logger.info(f"è½®æ¬¡ {round_idx+1}: å…¨å±€å­¦ä¹ ç‡={current_global_lr:.6f}, å®¢æˆ·ç«¯å­¦ä¹ ç‡={current_global_lr * client_lr_ratio:.6f}")

        # æ¯éš”5è½®è¿›è¡Œä¸€æ¬¡æœåŠ¡å™¨æœ‰æ•ˆæ€§éªŒè¯
        if (round_idx + 1) % 5 == 0:
            round_validation = validate_server_effectiveness(
                args, 
                client_models,
                server_model, 
                global_classifier,
                global_test_loader, 
                test_data_local_dict
            )
            
            # ğŸ”¥ è®¡ç®—å®¢æˆ·ç«¯ç‰¹å¾ç›¸ä¼¼åº¦ï¼ˆä½¿ç”¨ä¿®å¤åçš„å‡½æ•°ï¼‰
            try:
                from analyze.diagnostic_monitor import compute_client_feature_similarity_robust
                similarity = compute_client_feature_similarity_robust(
                    client_models, server_model, global_test_loader, device
                )
                logger.info(f"è½®æ¬¡ {round_idx+1} å®¢æˆ·ç«¯ç‰¹å¾å¹³å‡ç›¸ä¼¼åº¦: {similarity:.4f}")
                
                # è®°å½•åˆ°wandb
                if wandb.run:
                    wandb.log({"diagnostic/feature_similarity": similarity, "round": round_idx + 1})
                    
            except Exception as e:
                logger.warning(f"ç‰¹å¾ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {str(e)}")
            
            # è®°å½•éªŒè¯ç»“æœ
            try:
                wandb.log({
                    "round": round_idx + 1,
                    "validation/feature_quality": round_validation['feature_quality'],
                    "validation/heterogeneity_adaptation": round_validation['heterogeneity_adaptation'],
                    "validation/simple_classifier_acc": round_validation['simple_classifier_acc']
                })
            except Exception as e:
                logger.error(f"è®°å½•wandbéªŒè¯æŒ‡æ ‡å¤±è´¥: {str(e)}")
    
    # è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆæŠ¥å‘Š
    logger.info("=== æœ€ç»ˆè¯Šæ–­æŠ¥å‘Š ===")
    final_report = diagnostic_monitor.comprehensive_diagnostic_report(args.rounds - 1)
    
    logger.info(f"è®­ç»ƒå®Œæˆ! æœ€ä½³å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    logger.info(f"æœ€ç»ˆç³»ç»Ÿå¥åº·çŠ¶æ€: {final_report['overall_health'].upper()}")
    
    if final_report['critical_issues']:
        logger.error("é—ç•™çš„ä¸¥é‡é—®é¢˜:")
        for issue in final_report['critical_issues']:
            logger.error(f"  - {issue}")
    
    if final_report['recommendations']:
        logger.info("åç»­ä¼˜åŒ–å»ºè®®:")
        for rec in final_report['recommendations']:
            logger.info(f"  - {rec}")
    
    # å…³é—­wandb
    try:
        wandb.finish()
    except:
        pass

if __name__ == "__main__":
    main()